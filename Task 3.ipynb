{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9cb474-860b-44fc-8e9a-1526fa68f8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanni\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kanni\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import VisionEncoderDecoderModel, ViTFeatureExtractor, GPT2Tokenizer\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ImageCaptioning:\n",
    "    def __init__(self):\n",
    "        self.resnet_model = models.resnet50(pretrained=True)\n",
    "        self.resnet_model.eval()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        self.model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        self.feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "    \n",
    "    def extract_features(self, image_path):\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image).unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = self.resnet_model(image)\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def generate_caption(self, image_path):\n",
    "        image = Image.open(image_path)\n",
    "        inputs = self.feature_extractor(images=image, return_tensors=\"pt\").to(self.device)\n",
    "\n",
    "        output_ids = self.model.generate(inputs[\"pixel_values\"], max_length=16, num_beams=4, early_stopping=True)\n",
    "        \n",
    "        caption = self.tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        return caption\n",
    "\n",
    "    def display_image_with_caption(self, image_path, caption):\n",
    "        image = Image.open(image_path)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title(caption)\n",
    "        plt.show()\n",
    "\n",
    "image_captioning = ImageCaptioning()\n",
    "image_path = r\"C:\\Users\\kanni\\OneDrive\\Desktop\\codsoft tasks\\task 3 image.jpg\"\n",
    "\n",
    "features = image_captioning.extract_features(image_path)\n",
    "caption = image_captioning.generate_caption(image_path)\n",
    "print(\"Generated Caption:\", caption)\n",
    "\n",
    "image_captioning.display_image_with_caption(image_path, caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff7621-bd38-4cda-9a80-33b3e797281b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
